xbar <- 0
z <- (xbar - m) / (sd/sqrt(n))
2 * pt(-abs(z), df=n-1)
pt(0.975, df=8)
1100 + c(-1, 1)*qt(0.975, df=8) * 30 / sqrt(9)
n <- 4
xbar <- 0
c <- c(1, 1, 1, -1)
m <- mean(c)
sd <- sd(c)
z <- (xbar -m) / (sd/sqrt(n))
pt(-abs(z), df=n-1)
2 * pt(-abs(z), df=n-1)
t.test(c, alternative = c("greater"), mu=0)
t.test(c(1,1,1,0), alternative = c("greater"), mu=0)
t.test(c(1,1,1,0), alternative = c("greater"), mu=1)
m <- -4
sp <- sqrt((8 * 1.5^2 + 8 * 1.8^2)/16)
sd <- sp / (1/9 + 1/9)^.5
sd
z <- -4/sd
z
pt(z, 17, lower.tail = F)
pt(z, 17, lower.tail = T)
pt(-abs(z), 17, lower.tail = T)
pt(-abs(z), 8, lower.tail = T)
z <- qnorm(1 - 0.05)
mu0 <- 0.01
sigma <- 0.04
n <- 100
pnorm(mu0 + z * sigma/sqrt(n), mean=0, sd=sigma/sqrt(n), lower.tail = F)
pnorm(mu0 + z * sigma/sqrt(n), mean=1, sd=sigma/sqrt(n), lower.tail = F)
pnorm(-mu0 + z * sigma/sqrt(n), mean=0, sd=sigma/sqrt(n), lower.tail = F)
power.t.test(delta = 0.01, sd=0.04, sig.level = 0.05, power = 0.9, type = c("one.sample"), alternative = c("one.sided"))
power.t.test(delta = -0.01, sd=0.04, sig.level = 0.05, power = 0.9, type = c("one.sample"), alternative = c("one.sided"))
ppois(10, 0.01*1787, lower.tail = F)
ppois(10, 0.01*1787, lower.tail = T)
pbinom(3, 4, 0.5, lower.tail = T)
pbinom(3, 4, 0.5, lower.tail = F)
4 * 0.5^4 + 0.5^4
data(mtcars)
?lm
fit <- lm(mtcars$mpg ~ mtcars$wt + factor(mtcars$cyl))
fit
fit <- lm(mtcars$mpg ~ mtcars$wt + mtcars$hp +factor(mtcars$cyl))
fit
fit1 <- lm(mtcars$mpg ~ mtcars$hp +factor(mtcars$cyl))
fit1
fit <- lm(mtcars$mpg ~ mtcars$wt +factor(mtcars$cyl))
summary(fit)
fit1 <- lm(mtcars$mpg ~ mtcars$wt *factor(mtcars$cyl))
summary(fit1)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
f <- lm(y ~ x)
hatvalues(f)
dfbeta(f)
dfbetas(f)
?hatvalues
hat(f)
library("MASS")
?shuttle
head(shuttle)
unique(shuttle$use)
fit <- glm(shuttle$use ~ shuttle$wind, family = "binomial")
summary(fit)
unique(shuttle$wind)
exp(fit)
exp(fit$coefficients)
fit <- glm(shuttle$use ~ shuttle$wind + shuttle$magn, family = "binomial")
exp(fit$coefficients)
shuttle$notuse <- !shuttle$use
shuttle$notuse <- sapply
View(shuttle)
View(shuttle)
shuttle$notuse <- sapply(shuttle$use, function(x) { if(x == "auto") { "noauto"} else { "auto"}})
f <- glm(shuttle$notuse ~ shuttle$wind)
f <- glm(shuttle$notuse ~ shuttle$wind, family = "binomial")
class(shuttle$notuse)
unique(shuttle$notuse)
shuttle$notuse <- factor(shuttle$notuse)
f <- glm(shuttle$notuse ~ shuttle$wind, family = "binomial")
f
fit <- glm(shuttle$use ~ shuttle$wind, family = "binomial")
fit
data("InsectSprays")
head(InsectSprays)
f <- glm(InsectSprays$count ~ factor(InsectSprays$spray), family = "poisson")
f
exp(f$coefficients)
x <- -5:5
x
knot <- c(0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5)
xMat <- c(1, x, knot)
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
f <- lm(y ~ xMat -1)
xMat
xMat <- cbind(1, x, knot)
xMat
f <- lm(y ~ xMat -1)
f
plot(f)
plot(f)
plot(x, predict(f))
f
ff <- glm(InsectSprays$count ~ factor(InsectSprays$spray), family = "poisson")
ff
2.67415 / 0.05588
sum(InsectSprays$count)
ff <- glm(InsectSprays$count ~ factor(InsectSprays$spray), offset = log(685), family = "poisson")
?glm
ff <- glm(InsectSprays$count ~ factor(InsectSprays$spray), family = "poisson", offset = log(685))
ff <- glm(InsectSprays$count ~ factor(InsectSprays$spray), family = "poisson", offset = log(InsectSprays$count + 1))
ff
ff <- glm(InsectSprays$count ~ factor(InsectSprays$spray), family = "poisson")
ff$coefficients
(2.674 - 0.055) / 2.674
log(ff$coefficients)
exp(ff$coefficients)
library(AppliedPredictiveModeling)
install.packages("library(AppliedPredictiveModeling)")
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete
)
library(caret)
install.packages("caret")
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
summary(taining)
summary(training)
set.seed(3433
data(AlzheimerDisease)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(predictors)
names(predictors)
grep(names(predictors), "$IL")
?grep
grepl("$IL", names(predictors))
l <- grepl("$IL", names(predictors))
v <- names[l]
v <- names[predictors][l]
v <- names[predictors][[l]]
v <- names[predictors][l, ]
v <- names(predictors)[l]
v
v <- names(predictors)[l, ]
v <- names(predictors)[, l]
v
v <- names(predictors)[[l]
]
l
names(predictors)
names(predictors)[l, ]
names(predictors)[[l, ]]
names <- names(predictors)
v <- sapply(names, function(x) { if (grep("$IL", x) {x})})
v <- sapply(names, function(x) { if (grep("$IL", x)) {x}})
grep("$IL", "ILsd")
grep("$IL", "ILsd")
l
sum(l)
l <- grepl("^IL", names)
l
sum(l)
names[l]
v <- names[l]
v
?train
library(caret)
?train
predictors[v]
predictors[, v]
t <- train(training, predictors[, v], preProcess = "pca")
head(adData)
head(training)
t <- train(predictors[, v], training$diagnosis, data=training, preProcess = "pca")
t <- train(predictors[, v], training$diagnosis, data=training, preProcess = "pca")
t <- train(training$predictors[, v], training$diagnosis, data=training, preProcess = "pca")
t <- train(v, training$diagnosis, data=training, preProcess = "pca")
v
training[, v]
t <- train(training[, v], training$diagnosis, data=training, preProcess = "pca")
install.packages("e1071")
t <- train(training[, v], training$diagnosis, data=training, preProcess = "pca")
t
?preProcess
p <- preProcess(traing[, v], thresh = 0.8)
p <- preProcess(training[, v], thresh = 0.8)
p
p
summary(p)
p$numComp
p <- preProcess(training[, v], thresh = 0.8)
p$numComp
t <- training[, v]
t
summary(t)
p <- preProcess(t, thresh = 0.8)
p$numComp
summary(p)
p <- preProcess(t)
p$numComp
p <- preProcess(training)
p$numComp
class(trainning)
class(training)
class(training$IL_11)
p <- preProcess(predictors)
p
p$numComp
print(p$numComp)
p <- preProcess(training[, v], thresh = 0.8)
p
p <- preProcess(training[, v], thresh = 0.8)
p <- preProcess(training[, v], thresh = 0.8, verbose = T)
p
summary(p)
p$thresh
p$dim
p$method
data(BloodBrain)
preProc <- preProcess(bbbDescr)
summary(preProc)
preProc$pcaComp
preProc
preProc$rangeBounds
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?preProcess
l <- grepl("$IL", names(predictors))
naems
names
v <- names[l]
t <- training[, v]
p <- preProcess(t, method = "pca", thresh = 0.8)
p$numComp
p <- preProcess(t, method = c("pca"), thresh = 0.8)
p$numComp
p <- preProcess(t, method = c("PCA"), thresh = 0.8)
p <- preProcess(t, method = c("pca"), thresh = 0.8)
p <- preProcess(t, method = c("pca", "center", "scale"), thresh = 0.8)
summary(p)
p <- preProcess(t, method = c("pca", "center", "scale"), thresh = 0.8, pcaComp = 2)
p$numComp
p <- preProcess(log(t+1), method = c("pca", "center", "scale"), thresh = 0.8)
p$numComp
p <- preProcess(log(t+1), method = "pca", thresh = 0.8)
p
t
v
l
names[l]
names
l <- grepl("^IL", names)
l
v <- names[l]
t <- training[, v]
t
p <- preProcess(t, method = "pca", thresh = 0.8)
p$numComp
t
head(t)
class(t)
p
pp <- predict(p, t)
pp
?predict
?accuracy
??accuracy
?train
tt <- train(t, method = "glm")
View(t)
View(t)
tt <- train(t, training$diagnosis, method = "glm")
pp <- predict(tt, t)
confusionMatrix(training$diagnosis, pp)
confusionMatrix(pp, training$diagnosis)
p
?train
?train
tt2 <- train(t, training$diagnosis, preProcess = p)
tt2 <- train(t, training$diagnosis, method="glm", preProcess = "pca", trControl=trainControl(preProcOptions = list(thresh=0.8)))
confusionMatrix(training$diagnosis, tt2)
confusionMatrix(training$diagnosis, tt2$finalModel)
pp2 <- predict(tt2, t)
confusionMatrix(training$diagnosis, pp2)
data("concrete")
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
hist(training$Superplasticizer)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = segmentationOriginal[inTrain, ]
testing = segmentationOriginal[-inTrain, ]
head(training)
?train
t <- train(Case ~ ., data = training, method = "rpart")
predict(t, data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2))
predict(t, data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2))
t <- TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
t
test <- data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2)
test <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2)
test
test <- data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2)
test
predict(t, test)
View(training)
View(training)
?predict
?predict
predict(t$finalModel, test)
predict(t, type = "class")
predict(t)
t
names <- names(training)
names
names <- names[-Case]
names <- names[-2]
names
names <- names(training)
names
length(names)
names <- names[-2]
length(names)
?data.frame
data.frame(col.names = names)
data.frame(names)
test
predict(t, test, na.action = na.rpart)
predict(t, test, na.action = "na.rpart")
predict(t, test, na.action = na.omit)
tt <- testing[1, ]
tt
class(tt)
name
names
d <- data.frame()
d
colnames(d) <- names
d <- data.frame(1:118)
d
predict(t, newdata=test, na.action = na.omit)
df <- data.frame(matrix(ncol = 118, nrow = 0))
colnames(df) <- names
df
df$TotalIntenCh2 <- 23000
test
rbind(df, test)
df
dd <- rbind(df, test)
dd
dd <- rbind(test,df)
dd
dd$TotalIntench2 <- 0
dd
test
df <- data.frame(matrix(ncol = 118, nrow = 1))
df
colnames(df) <- names
df
df$TotalIntenCh2 <- 23000
df$FiberWidthCh1 <- 10
df$PerimStatusCh1 <- 2
df
predict(t, df)
predict(t, df, na.action = na.omit())
predict(t, df, na.action = na.omit
)
class(traing$Class)
class(training$Class)
df <- testing[1, ]
df
df[, ] <- NA
df
df$TotalIntenCh2 <- 23000
df$FiberWidthCh1 <- 10
df$PerimStatusCh1 <- 2
df
predict(t, df)
class(df$Class)
df$Class <- as.factor(df$Class)
predict(t, df)
predict(t, df, na.action = na.omit)
df
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data("vowel.train")
data("vowel.test")
head(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(caret)
?train
m1 <- train(y ~ ., data = vowel.train, method = "rf")
p1 <- predict(m1, newdata = vowel.test)
p1
summary(p1)
confusionMatrix(p1, vowel.test$y)
m2 <- train(y ~ ., data = vowel.train, method = "gbm")
p2 <- predict(m2, newdata = vowel.test)
confusionMatrix(p2, vowel.test$y)
p <- p1 == p2
sum(p)
len(p)
length(p)
319 / 462.0
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
m1 <- train(diagnosis ~ predictors, data=training, method="rf")
m1 <- train(training$diagnosis ~ training$predictors, data=training, method="rf")
m1 <- train(diagnosis ~ ., data=training, method="rf")
m2 <- train(diagnosis ~ ., data=training, method="gbm")
m2 <- train(diagnosis ~ ., data=training, method="lda")
m3 <- train(diagnosis ~ ., data=training, method="lda")
m2 <- train(diagnosis ~ ., data=training, method="lda")
m3 <- train(diagnosis ~ ., data=training, method="lda")
m2 <- train(diagnosis ~ ., data=training, method="gbm")
p1 <- predict(m1, newdata = testing)
p2 <- predict(m2, newdata = testing)
p3 <- predict(m3, newdata = testing)
p <- data.frame(p1, p2, p3, diagnosis = testing$diagnosis)
m <- train(diagnosis ~ ., data = p, method="rf")
r <- predict(m, testing)
confusionMatrix(r, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
m <- train(CompressiveStrength ~ ., data = training, method="lasso")
m
?plot.enet
plot(m, xvar=c("fraction"))
plot(m, xvar=c("L1norm"))
head(training)
head(training)
plot(m, xvar=c("L1norm"), use.color=T)
summary(m)
m$modelInfo
m <- train(CompressiveStrength ~ ., data = training, method="lasso")
coef(m)
coefficients(m)
plot(m, xvar="penalty")
p <- plot(m, xvar="penalty")
p
summary(p)
p <- plot(m, xvar=c("penalty"))
p
p <- plot(m, xvar=c("penalty"))
p
setwd("~/opensource/datasciencecoursera")
setwd("~/opensource/datasciencecoursera/practicalML")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "./pml-training.csv", method="curl")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "./pml-testing.csv", method="curl")
ls
dir()
?fancyRpartPlot
download.packages("rattle")
install.packages("rattle")
?fancyRpartPlot
??fancyRpartPlot
lirary(rattle)
library(rattle)
?fancyRpartPlot
knitr::opts_chunk$set(echo = TRUE)
GBM <- train(calsse ~ ., data = trainData, method = "gbm", trControl = trControl, verbose = FALSE)
